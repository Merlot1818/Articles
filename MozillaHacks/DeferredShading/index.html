<html>
<head>
<title>WebGL Deferred Shading</title>
</head>
<body>
<link rel="stylesheet" href="index.css" type="text/css" />
<div id = "content-main">
<h2>WebGL Deferred Shading</h2>
<p class="authors"><span>by</span> Sijie Tian, Yuqin Shao and Patrick Cozzi</p>

<p>
WebGL brings hardware-accelerated 3D graphics to the web.  Many features of <a href="https://wiki.mozilla.org/Platform/GFX/WebGL2" target="_blank">WebGL 2</a> are available today as WebGL extensions.  In this article, we describe how to use the <a href="http://www.khronos.org/registry/webgl/extensions/WEBGL_draw_buffers/">WEBGL_draw_buffers</a> extension to create a scene with a large number of dynamic lights using a technique called deferred shading, which is popular among AAA games.
</p>
<p>
<img src="DeferredShadingPic1.png" />
</p>
<p>
<a href="https://vimeo.com/82070755">video</a> &bullet;
<a href="http://sijietian.com/WebGL/deferredshading/index.html">live demo</a> &bullet;
<a href="https://github.com/YuqinShao/Tile_Based_WebGL_DeferredShader">source code</a>
</p>
<p>
Today, most WebGL engines use forward shading, where lighting is computed in the same pass that geometry is transformed.  This makes it difficult to support a large number of dynamic lights and different light types.
</p>
<p>
Forward shading can use a pass per light.  Rendering a scene looks like:
</p>
<pre>
foreach light {
  foreach visible mesh {
    if (light volume intersects mesh) {
      render using shader for this material/light;
      accumulate in framebuffer using blending;
    }
  }
}
</pre>
<p>
This requires a different shader for each material/light-type combination, which adds up.  From a performance perspective, each mesh needs to be rendered (vertex transform, rasterization, material part of the fragment shader, etc.) once per light instead of just once, and occluded fragments are still shaded unless front-to-back sorting or a z-prepass is used.  In addition, even if a light's volume intersects a mesh, it may only affect a small part of the mesh, but the entire mesh is still rendered.
</p>
<p>
Forward shading can also use a single pass rendering a scene like:
</p>
<pre>
foreach visible mesh {
  find lights affecting mesh;
  Render all lights and materials using a single shader;
}
</pre>
<p>
Although meshes are only rendered once, this has the same performance drawbacks for occluded fragments.  The biggest drawback is the number of shaders required since a different shader is required for each material/light (not light type) combination.  This makes shaders harder to author, increases compile times, usually requires runtime compiling, and increases the number of shaders to sort by.
</p>

<h2>Deferred Shading</h2>
Deferred shading takes a different approach than forward shading by dividing rendering into two passes: one that transforms the geometry and writes positions, normals, and material properties to textures called the g-buffer, and another that performs lighting as a series of screen-space post-processing effects.  These are called the g-buffer pass and light accumulation pass, respectively.
<pre>
// g-buffer pass
foreach visible mesh {
  write material properties to g-buffer;
}

// light accumulation pass
foreach light {
  compute light by reading g-buffer;
  accumulate in framebuffer;
}
</pre>
<p>
This decouples lighting from scene complexity and only requires one shader per material and per light type.  Since lighting takes place in screen-space, occluded fragments are not shaded, essentially bringing the depth complexity down to one.  There are also downsides such as its high memory bandwidth usage and making translucency and anti-aliasing difficult.
</p>
<p>
Until recently, WebGL had a roadblock for implementing deferred shading.  In WebGL, a fragment shader could only write to a single texture/renderbuffer.  With deferred shading, the g-buffer is usually composed of several textures.  This means that the scene needed to be rendered multiple times during the g-buffer pass.
</p>

<h2>WEBGL_draw_buffers</h2>
<p>
Now with the WEBGL_draw_buffers extension, a fragment shader can write to several textures.  To use this extension in Firefox, browse to <span class="code">about:config</span> and turn on <span class="code">webgl.enable-draft-extensions</span>.  Then, to make sure your system supports WEBGL_draw_buffers, browse to <a href="http://webglreport.com/">webglreport.com</a> and verify it is in the list of extensions at the bottom of the page.
</p>
<img src="DeferredShadingPic2.png"/>
<p>
To use the extension, first initialize it:
</p>
<pre lang="javascript">
var ext = gl.getExtension('WEBGL_draw_buffers');
if (!ext) {
  // ...
}
</pre>
<p>
We can now bind multiple textures, <span class="code">tx[]</span> in the example below, to different framebuffer color attachments.
</p>
<pre lang="javascript">
var fb = gl.createFramebuffer();
gl.bindFramebuffer(gl.FRAMEBUFFER, fb);
gl.framebufferTexture2D(gl.FRAMEBUFFER, ext.COLOR_ATTACHMENT0_WEBGL, gl.TEXTURE_2D, tx[0], 0);
gl.framebufferTexture2D(gl.FRAMEBUFFER, ext.COLOR_ATTACHMENT1_WEBGL, gl.TEXTURE_2D, tx[1], 0);
gl.framebufferTexture2D(gl.FRAMEBUFFER, ext.COLOR_ATTACHMENT2_WEBGL, gl.TEXTURE_2D, tx[2], 0);
gl.framebufferTexture2D(gl.FRAMEBUFFER, ext.COLOR_ATTACHMENT3_WEBGL, gl.TEXTURE_2D, tx[3], 0);
</pre>
<p>
For debugging, we can check to see if the attachments are compatible by calling <span class="code">gl.checkFramebufferStatus</span>.  This function is slow and should not be called often in release code.
</p>
<pre>
if (gl.checkFramebufferStatus(gl.FRAMEBUFFER) !== gl.FRAMEBUFFER_COMPLETE) {
  // Can't use framebuffer.
  // See http://www.khronos.org/opengles/sdk/docs/man/xhtml/glCheckFramebufferStatus.xml
} 
</pre>
<p>
Next, we map the color attachments to draw buffer slots that the fragment shader will write to using <code> gl_FragData</code>.
</p>
<pre lang="javascript">
ext.drawBuffersWEBGL([
  ext.COLOR_ATTACHMENT0_WEBGL, // gl_FragData[0]
  ext.COLOR_ATTACHMENT1_WEBGL, // gl_FragData[1]
  ext.COLOR_ATTACHMENT2_WEBGL, // gl_FragData[2]
  ext.COLOR_ATTACHMENT3_WEBGL  // gl_FragData[3]
]);
</pre>
<p>
The maximum size of the array passed to <span class="code">drawBuffersWEBGL</span> depends on the system and can be queried by calling <span class="code">gl.getParameter(gl.MAX_DRAW_BUFFERS_WEBGL)</span>.  In GLSL, this is also available as <span class="code">gl_MaxDrawBuffers</span>.
</p>
<p>
In the deferred shading geometry pass, the fragment shader writes to multiple textures.  A trivial pass-through fragment shader is:
</p>
<pre>
#extension GL_EXT_draw_buffers : require
precision highp float;
void main(void) {
  gl_FragData[0] = vec4(0.25);
  gl_FragData[1] = vec4(0.5);
  gl_FragData[2] = vec4(0.75);
  gl_FragData[3] = vec4(1.0);
}
</pre>
<p>
Even though we initialized the extension in JavaScript with <span class="code">gl.getExtension</span>, the GLSL code still needs to include <span class="code">#extension GL_EXT_draw_buffers : require</span> to use the extension.  With the extension, the output is now the <span class="code">gl_FragData</span> array that maps to framebuffer color attachments, not <span class="code">gl_FragColor</span>, which is traditionally the output.
</p>

<h2>g-buffers</h2>
<p>
In our deferred shading implementation the g-buffer is composed of four textures: eye-space position, eye-space normal, color, and depth.  Position, normal, and color use the floating-point RGBA format via the <a href="http://www.khronos.org/registry/webgl/extensions/OES_texture_float/" target="_blank">OES_texture_float</a> extension, and depth uses the unsigned-short <span class="code">DEPTH_COMPONENT</span> format.
</p>
<p>
<p>
Position texture
<img src="position.png"/>
</p>
<p>
Normal texture
<img src="normal.png"/>
</p>
<p>
Color texture
<img src="color.png"/>
</p>
Depth texture
<img src="depth.png"/>
</p>
<p>
Light accumulation using g-buffers
<img src="layout.png"/>
</p>
<p>
This g-buffer layout is simple for our testing.  Although four textures is common for a full deferred shading engine, an optimized implementation would try to use the least amount of memory by lowering precision, reconstructing position from depth, packing values together, using different distributions, and so on.
</p>
<p>
With WEBGL_draw_buffers, we can use a single pass to write each texture in the g-buffer.  Compared to using a single pass per texture, this improves performance and reduces the amount of JavaScript code and GLSL shaders.  As shown in the graph below, as scene complexity increases so does the benefit of using WEBGL_draw_buffers.  Since increasing scene complexity requires more <span class="code">drawElements</span>/<span class="code">drawArrays</span> calls, more JavaScript overhead, and transforms more triangles, WEBGL_draw_buffers provides a benefit by writing the g-buffer in a single pass, not a pass per texture.
</p>
<p>
<img src="drawbufferextesnionwithdragons.png"/>
</p>
<p>
All performance numbers were measured using an NVIDIA GT 620M in FireFox 25.0.1 on Window 8.  In the above graph, 20 point lights were used. The light intensity decreases proportionally to the square of distance between the current position and the light position.  Each Stanford Dragon is 100,000 triangles and requires five draw calls so, for example, when 50 dragons are rendered, 250 draw calls (and related state changes) are issued, and a total of 5,000,000 triangles are transformed.
</p>
<p>
<img src="DeferredShadingPic7.png"/>
WEBGL_draw_buffers test scene, shown here with 100 Stanford Dragons.
</p>
<p>
Of course, when scene complexity is very low, like the case of one dragon, the cost of the g-buffer pass is low so the savings from WEBGL_draw_buffers are minimal, especially if there are many lights in the scene, which drives up the cost of the light accumulation pass as shown in the graph below. 
</p>
<p>
<img src="drawbufferextesnionwithlights.png"/>
</p>

<p>
Deferred shading requires a lot of GPU memory bandwidth, which can hurt performance and increase power usage.  After the g-buffer pass, a naive implementation of the light accumulation pass would render each light as a full-screen quad and read the entirety of each g-buffer.  Since most light types, like point and spot lights, attenuate and have a limited area of influence, the full-screen quad can be replaced with a world-space bounding volume or tight screen-space bounding rectangle.
</p>
<h2>Tile-Based Deferred Shading</h2>
<p>
Tile-based deferred shading takes this a step farther and splits the screen into tiles, for example 16x16 pixels, and then determines which lights influence each tile.  Light-tile information is then passed to the shader and the g-buffer is only read once for all lights. Since this drastically reduces memory bandwidth, it improves performance.  The following graph shows performance for the sponza scene (66,450 triangles and 38 draw calls) at 1024x768 with 32x32 tiles.
<p>
<p>
<img src="DeferredShadingPic5.png"/>
</p>
<p>
Tile size affects performance.  Smaller tiles require more JavaScript overhead to create light-tile information, but less computation in the lighting shader.  Larger tiles have the opposite tradeoff.  Therefore, choosing a suitable tile is important for the performance. The figure below is shown the relationship between tile size and performance with 100 lights.
</p>
<p>
<img src="DeferredShadingPic8.png"/>
</p>
<p>
A visualization of the number of lights in each tile is shown below.  Black tiles have no lights intersecting them and white tiles have the most lights.
</p>
<p>
<img src="TileDebugView.png"/>
</p>
<h2>Conclusion</h2>
<p>
WEBGL_draw_buffers is a useful extension for improving the performance of deferred shading in WebGL.  Checkout the <a href="http://sijietian.com/WebGL/deferredshading/index.html">live demo</a> and our <a href="https://github.com/YuqinShao/Tile_Based_WebGL_DeferredShader">code</a> on github.
</p>
<h2>Acknowledgements</h2>
<p>
We implemented this project for the course <a href="http://www.seas.upenn.edu/~cis565/" target="_blank">CIS 565: GPU Programming and Architecture</a>, which is part of the <a href="http://cg.cis.upenn.edu/" target="_blank">computer graphics program</a> at the University of Pennsylvania.  We thank <a href="http://liamboone.blogspot.com/" target="_blank">Liam Boone</a> for his support and <a href="http://erich.realtimerendering.com/" target="_blank">Eric Haines</a> for reviewing this article.
</p>
<h2>References</h2>
<p>

<ul>
  <li><a href="http://www.guerrilla-games.com/publications/dr_kz2_rsx_dev07.pdf" target="_blank">Deferred Rendering in Killzone 2</a> by Michal Valient</li>
  <li><a href="http://www.slideshare.net/cagetu/light-prepass" target="_blank">Light Pre-Pass</a> by Wolfgang Engel</li>
  <li><a href="http://aras-p.info/texts/CompactNormalStorage.html" target="_blank">Compact Normal Storage for Small 
G-Buffers</a> by Aras Pranckevicius</li>
  <li><a href="http://www.cse.chalmers.se/~uffe/tiled_shading_preprint.pdf" target="_blank">Tiled Shading</a> by Ola Olsson and Ulf Assarsson</li>
  <li><a href="http://bps10.idav.ucdavis.edu/talks/12-lauritzen_DeferredShading_BPS_SIGGRAPH2010_Notes.pdf" target="_blank">Deferred Rendering for Current and Future Rendering Pipelines</a> by Andrew Lauritzen</li>

</ul>
</p>

</body>
</html>